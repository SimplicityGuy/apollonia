---
name: Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  AMQP_CONNECTION_STRING: amqp://test:test@localhost:5672/
  NEO4J_URI: bolt://localhost:7687
  NEO4J_USER: neo4j
  NEO4J_PASSWORD: testpassword

jobs:
  # Python unit tests
  python-tests:
    name: Python Tests
    runs-on: ubuntu-latest

    permissions:
      contents: read
      checks: write
      pull-requests: write

    strategy:
      matrix:
        python-version: ['3.12']

    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ðŸ“¦ Install uv
        uses: astral-sh/setup-uv@v2
        with:
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: ðŸ Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Install just
        uses: extractions/setup-just@e33e0265a09d6d736e2ee1e0eb685ef1de4669ff # v3.0.0
        with:
          just-version: '1.38.0'  # Pin to specific version for reliability

      - name: ðŸ“¦ Install dependencies
        run: uv sync --frozen --all-extras

      - name: ðŸ§ª Run unit tests with coverage
        run: just test-coverage

      - name: ðŸ“¤ Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.python-version == '3.12'
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          name: apollonia-coverage
          fail_ci_if_error: false

      - name: ðŸ“¤ Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pytest-results-py${{ matrix.python-version }}
          path: |
            pytest-results.xml
            htmlcov/

      - name: ðŸ“Š Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always() && matrix.python-version == '3.12'
        with:
          files: pytest-results.xml
          comment_mode: failures
          check_name: Python Test Results

  # Frontend tests
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest

    permissions:
      contents: read
      checks: write

    defaults:
      run:
        working-directory: frontend

    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: Install just
        uses: extractions/setup-just@e33e0265a09d6d736e2ee1e0eb685ef1de4669ff # v3.0.0
        with:
          just-version: '1.38.0'  # Pin to specific version for reliability

      - name: ðŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: ðŸ“¦ Install dependencies
        run: cd frontend && npm install

      - name: ðŸ§ª Run tests with coverage
        run: just test-frontend

      - name: ðŸ“¤ Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./frontend/coverage/lcov.info
          flags: frontend
          name: apollonia-frontend-coverage
          fail_ci_if_error: false

      - name: ðŸ“¤ Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-test-results
          path: frontend/coverage/

  # Integration tests with services
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [python-tests]

    permissions:
      contents: read
      checks: write

    services:
      rabbitmq:
        image: rabbitmq:3-management-alpine
        ports:
          - 5672:5672
          - 15672:15672
        env:
          RABBITMQ_DEFAULT_USER: test
          RABBITMQ_DEFAULT_PASS: test
        options: >-
          --health-cmd "rabbitmq-diagnostics ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      postgres:
        image: postgres:15-alpine
        ports:
          - 5432:5432
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: apollonia_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      neo4j:
        image: neo4j:5-community
        ports:
          - 7474:7474
          - 7687:7687
        env:
          NEO4J_AUTH: neo4j/testpassword
        options: >-
          --health-cmd "neo4j status"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ðŸ“¦ Install uv
        uses: astral-sh/setup-uv@v2
        with:
          enable-cache: true

      - name: Install just
        uses: extractions/setup-just@e33e0265a09d6d736e2ee1e0eb685ef1de4669ff # v3.0.0
        with:
          just-version: '1.38.0'  # Pin to specific version for reliability

      - name: ðŸ Set up Python 3.12
        run: uv python install 3.12

      - name: ðŸ“¦ Install dependencies
        run: uv sync --frozen --all-extras

      - name: ðŸ”— Run integration tests
        env:
          POSTGRES_URL: postgresql://test:test@localhost:5432/apollonia_test
          REDIS_URL: redis://localhost:6379/0
        run: just test-integration

      - name: ðŸ“¤ Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            integration-results.xml
            coverage.xml

  # End-to-end tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, frontend-tests]

    permissions:
      contents: read
      checks: write

    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ðŸ“¦ Install uv
        uses: astral-sh/setup-uv@v2

      - name: Install just
        uses: extractions/setup-just@e33e0265a09d6d736e2ee1e0eb685ef1de4669ff # v3.0.0
        with:
          just-version: '1.38.0'  # Pin to specific version for reliability

      - name: ðŸ Set up Python 3.12
        run: uv python install 3.12

      - name: ðŸ“¦ Install dependencies
        run: uv sync --frozen --all-extras

      - name: ðŸ“¦ Setup Node.js for frontend
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: ðŸ“¦ Install frontend dependencies
        run: cd frontend && npm install

      - name: ðŸŒ Run E2E tests
        run: just test-e2e

      - name: ðŸ“‹ Show service logs on failure
        if: failure()
        run: |
          echo "ðŸ” Service logs:"
          docker-compose logs

      - name: ðŸ›‘ Stop services
        if: always()
        run: docker-compose down -v

      - name: ðŸ“¤ Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: e2e-results.xml

  # Test summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [python-tests, frontend-tests, integration-tests, e2e-tests]
    if: always()

    steps:
      - name: ðŸ“Š Test Results Summary
        run: |
          echo "## ðŸ§ª Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Python Tests | ${{ needs.python-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ needs.e2e-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
