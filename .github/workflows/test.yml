---
name: Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  AMQP_CONNECTION_STRING: amqp://test:test@localhost:5672/
  NEO4J_URI: bolt://localhost:7687
  NEO4J_USER: neo4j
  NEO4J_PASSWORD: testpassword

jobs:
  # Python unit tests
  python-tests:
    name: Python Tests
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: ['3.12']

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 📦 Install uv
        uses: astral-sh/setup-uv@v2
        with:
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: 🐍 Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: 📦 Install dependencies
        run: uv sync --frozen --all-extras

      - name: 🧪 Run unit tests with coverage
        run: |
          uv run pytest -v \
            --cov=ingestor \
            --cov=populator \
            --cov=analyzer \
            --cov=api \
            --cov=shared \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-report=html \
            --junit-xml=pytest-results.xml \
            tests/unit tests/ingestor tests/populator tests/analyzer

      - name: 📤 Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.python-version == '3.12'
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          name: apollonia-coverage
          fail_ci_if_error: false

      - name: 📤 Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pytest-results-py${{ matrix.python-version }}
          path: |
            pytest-results.xml
            htmlcov/

      - name: 📊 Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always() && matrix.python-version == '3.12'
        with:
          files: pytest-results.xml
          comment_mode: failures
          check_name: Python Test Results

  # Frontend tests
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: frontend

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: 📦 Install dependencies
        run: npm install

      - name: 🧪 Run tests with coverage
        run: npm run test:coverage

      - name: 📤 Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./frontend/coverage/lcov.info
          flags: frontend
          name: apollonia-frontend-coverage
          fail_ci_if_error: false

      - name: 📤 Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-test-results
          path: frontend/coverage/

  # Integration tests with services
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [python-tests]

    services:
      rabbitmq:
        image: rabbitmq:3-management-alpine
        ports:
          - 5672:5672
          - 15672:15672
        env:
          RABBITMQ_DEFAULT_USER: test
          RABBITMQ_DEFAULT_PASS: test
        options: >-
          --health-cmd "rabbitmq-diagnostics ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      postgres:
        image: postgres:15-alpine
        ports:
          - 5432:5432
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: apollonia_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      neo4j:
        image: neo4j:5-community
        ports:
          - 7474:7474
          - 7687:7687
        env:
          NEO4J_AUTH: neo4j/testpassword
        options: >-
          --health-cmd "neo4j status"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 📦 Install uv
        uses: astral-sh/setup-uv@v2
        with:
          enable-cache: true

      - name: 🐍 Set up Python 3.12
        run: uv python install 3.12

      - name: 📦 Install dependencies
        run: uv sync --frozen --all-extras

      - name: 🔗 Run integration tests
        env:
          POSTGRES_URL: postgresql://test:test@localhost:5432/apollonia_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          uv run pytest -v \
            --cov=ingestor \
            --cov=populator \
            --cov=analyzer \
            --cov-report=xml \
            --junit-xml=integration-results.xml \
            tests/integration

      - name: 📤 Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            integration-results.xml
            coverage.xml

  # End-to-end tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, frontend-tests]

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 📦 Install uv
        uses: astral-sh/setup-uv@v2

      - name: 🐍 Set up Python 3.12
        run: uv python install 3.12

      - name: 📦 Install dependencies
        run: uv sync --frozen --all-extras

      - name: 📦 Setup Node.js for frontend
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: 📦 Install frontend dependencies
        run: cd frontend && npm install

      - name: 🐳 Start services with Docker Compose
        run: |
          echo "🚀 Starting services..."
          docker-compose up -d
          echo "⏳ Waiting for services to be ready..."
          sleep 30
          docker-compose ps

      - name: 🌐 Run E2E tests
        run: |
          uv run pytest -v \
            --junit-xml=e2e-results.xml \
            tests/e2e

      - name: 📋 Show service logs on failure
        if: failure()
        run: |
          echo "🔍 Service logs:"
          docker-compose logs

      - name: 🛑 Stop services
        if: always()
        run: docker-compose down -v

      - name: 📤 Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: e2e-results.xml

  # Test summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [python-tests, frontend-tests, integration-tests, e2e-tests]
    if: always()

    steps:
      - name: 📊 Test Results Summary
        run: |
          echo "## 🧪 Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Python Tests | ${{ needs.python-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ needs.e2e-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
