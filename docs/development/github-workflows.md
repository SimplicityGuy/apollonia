# GitHub Workflows Documentation

Apollonia uses GitHub Actions for comprehensive CI/CD automation. The workflows are designed with a
DevOps-first approach, emphasizing security, quality, reliability, and performance.

## ðŸš€ Recent Improvements

### Performance Enhancements

- **Reusable Composite Actions**: DRY principle implementation with shared setup workflows
- **Intelligent Change Detection**: Tests only run when relevant files change
- **Parallel Test Execution**: Tests split by type for concurrent execution
- **Enhanced Caching**: Multi-layer caching for dependencies, Docker layers, and test results
- **Comprehensive Timeouts**: All jobs and long-running steps have appropriate timeouts

### Composite Actions

Located in `.github/actions/`:

- **`setup-python-env`**: Standardized Python environment setup with uv and caching
- **`setup-frontend-env`**: Node.js setup with npm caching and dependency installation
- **`upload-coverage`**: Reusable coverage upload to Codecov with proper flags
- **`wait-for-services`**: Parallel health checks for Docker services
- **`security-scan`**: Combined security scanning for Python and JavaScript

## Workflow Architecture

### Simplified Structure

The workflow system has been streamlined to eliminate duplication:

1. **`ci.yml`**: Main entry point for all CI/CD operations
1. **Individual workflows**: Now only callable (no push/PR triggers)
1. **Reusable actions**: DRY principle implementation
1. **Scheduled workflows**: Benchmarks and dependency updates

## Workflow Overview

### Main Pipeline (`ci.yml`)

The unified CI/CD pipeline that orchestrates all checks:

- **Triggers**: Push to main, PRs, manual dispatch
- **Dependencies**: quality â†’ tests + security â†’ docker
- **Timeout**: Jobs range from 5-30 minutes
- **Features**:
  - Integrated security scanning for all runs
  - Dependency review for PRs
  - Optional test skipping for quick iterations
  - Docker image push control
  - Overall status reporting

### Performance Benchmarks (`benchmarks.yml`)

Dedicated workflow for performance tracking:

- **Triggers**: Weekly schedule (Sundays 2 AM UTC), manual dispatch, main branch pushes
- **Features**:
  - Historical performance tracking
  - Automatic regression detection (>150% threshold)
  - GitHub Pages deployment for results
  - Alert comments on performance degradation

### Quality Checks (`quality.yml`)

Fast feedback loop for code quality:

- **Purpose**: Quick validation of code standards
- **Scope**: Python linting, formatting, type checking, frontend quality
- **Tools**: Ruff, mypy, ESLint, Prettier, bandit
- **Runtime**: ~3-5 minutes (10 min timeout per job)
- **Features**:
  - Parallel backend and frontend quality checks
  - Pre-commit hook validation
  - Security analysis with bandit

### Testing Suite (`test.yml`)

Comprehensive testing pipeline with intelligent optimization:

- **Change Detection**: Skip tests when no relevant files changed
- **Parallel Execution**: Tests split into concurrent groups
- **Test Groups**:
  - Python unit tests (15 min timeout)
  - Python integration-unit tests (15 min timeout)
  - Frontend tests (15 min timeout)
  - Integration tests with real services (20 min timeout)
  - E2E tests with Docker (30 min timeout)
- **Caching**:
  - Test results and coverage data
  - Docker layers for E2E tests
  - Integration test fixtures
- **Coverage**: Parallel coverage aggregation and Codecov integration

### Docker Build (`docker.yml`)

Container build and registry pipeline:

- **Service Discovery**: Auto-detects services with Dockerfiles
- **Build Performance**:
  - Parallel service builds (30 min timeout)
  - Docker layer caching with buildx
  - Frontend build optimization (20 min timeout)
- **Security**: Trivy vulnerability scanning before push
- **Registry**: GitHub Container Registry (ghcr.io)
- **Integration Testing**: Multi-service deployment validation (15 min timeout)

### Dependencies (`dependencies.yml`)

Automated dependency management:

- **Schedule**: Weekly on Monday at 2 AM UTC
- **Scope**: Python (uv) and Node.js packages
- **Update Levels**: Patch, minor, major, or all updates
- **Testing**: Runs test suite before creating PR (15 min timeout)
- **Security**: Vulnerability scanning (10 min timeout)
- **Automation**: Creates PRs with detailed test results

## Workflow Features

### ðŸ”’ Security-First Design

**Multi-layer Security Scanning**:

- **Trivy**: Container vulnerability scanning
- **CodeQL**: Static code analysis
- **Bandit**: Python security linting
- **pip-audit**: Python dependency scanning
- **npm audit**: Node.js dependency scanning

**SARIF Integration**: Security findings uploaded to GitHub Security tab

**Secrets Management**: Minimal secret usage with GitHub token authentication

### ðŸ“Š Quality Gates

**8-Step Validation Cycle with AI Integration**:

1. Syntax validation with language parsers
1. Type checking with mypy/TypeScript
1. Linting and formatting with Ruff/ESLint
1. Security scanning with bandit/npm audit
1. Unit testing with pytest/vitest (â‰¥80% coverage)
1. Integration testing with real services (â‰¥70% coverage)
1. E2E testing with Playwright
1. Deployment validation

### âš¡ Performance Optimizations

**Intelligent Caching Strategy**:

- **Python**: uv cache, pip cache, virtual environments
- **Node.js**: npm cache, node_modules caching
- **Docker**: Multi-layer buildx caching
- **Tests**: Result caching, coverage data persistence

**Parallel Execution**:

- **Test Parallelization**: `-n auto` for pytest using all CPU cores
- **Service Health Checks**: Parallel startup verification
- **Job Concurrency**: Independent jobs run simultaneously
- **Matrix Strategies**: Efficient test group distribution

**Resource Management**:

- **Timeouts**: Prevent hanging workflows and save CI minutes
- **Concurrency Controls**: Prevent resource conflicts
- **Smart Cancellation**: Outdated runs cancelled automatically
- **Change Detection**: Skip unnecessary work based on file changes

### ðŸŽ¯ Developer Experience

**Visual Feedback**:

- Emoji-enhanced step names for better readability
- Comprehensive status summaries
- Performance tips when tests are skipped
- Clear timeout indicators

**Fast Feedback**:

- Quality checks complete in ~3-5 minutes
- Parallel test execution across groups
- Early failure detection with fail-fast
- Intelligent test skipping

**Reusable Components**:

- Composite actions eliminate duplication
- Standardized setup across all workflows
- Consistent caching strategies
- Maintainable configuration

## Environment Variables

### Required Secrets

```bash
# Docker registry (automatic)
GITHUB_TOKEN=<automatic>

# Code coverage
CODECOV_TOKEN=<optional>

# Notifications
DISCORD_WEBHOOK=<optional>
SLACK_WEBHOOK=<optional>

# Container registry (automatic)
GHCR_TOKEN=<automatic>
```

### Workflow Environment Variables

```yaml
# Container registry settings
REGISTRY: ghcr.io
IMAGE_NAME: ${{ github.actor }}/apollonia

# Test database settings
AMQP_CONNECTION_STRING: amqp://test:test@localhost:5672/
NEO4J_URI: bolt://localhost:7687
NEO4J_USER: neo4j
NEO4J_PASSWORD: testpassword
```

## Triggering Workflows

### Automatic Triggers

**On every push to main**:

- Quality checks (only if source files changed)
- Full test suite (only if relevant files changed)
- Docker builds (with push to registry)
- Security scanning

**On every pull request**:

- Quality checks (only if source files changed)
- Full test suite (only if relevant files changed)
- Docker builds (no registry push)
- Dependency review

**Weekly schedule**:

- Dependency updates (Monday 2 AM UTC)
- Full pipeline run (Saturday 1 AM UTC)

### Manual Triggers

**Workflow Dispatch Options**:

```bash
# Force Docker image push from PR
gh workflow run docker.yml -f push_images=true

# Dependency update with specific level
gh workflow run dependencies.yml -f update_type=minor

# Run full test suite regardless of changes
gh workflow run test.yml
```

## Monitoring and Observability

### Status Badges

Add to your README:

```markdown
![CI/CD](https://github.com/username/apollonia/actions/workflows/ci.yml/badge.svg)
![Benchmarks](https://github.com/username/apollonia/actions/workflows/benchmarks.yml/badge.svg)
![Dependencies](https://github.com/username/apollonia/actions/workflows/dependencies.yml/badge.svg)
```

### Performance Metrics

**Workflow Efficiency**:

- Change detection reduces unnecessary test runs by ~40%
- Parallel execution cuts test time by ~60%
- Caching saves ~70% on dependency installation
- Timeouts prevent resource waste

**Test Performance**:

- Unit tests: \<5 minutes with parallelization
- Integration tests: \<10 minutes with service optimization
- E2E tests: \<15 minutes with Docker caching

### Notifications

**Discord Integration**:

- Build status notifications
- Docker build completions
- Security alert summaries

**GitHub Features**:

- PR status checks with detailed feedback
- Workflow summaries in PR comments
- Security alerts in Security tab

## Development Workflow Integration

### Local Development

```bash
# Run quality checks locally (matches CI)
just check

# Run specific test groups (like CI)
just test-unit
just test-integration

# Build Docker images with caching
just build-docker

# Full CI simulation
just ci
```

### Using Composite Actions Locally

The composite actions can be tested locally:

```bash
# Simulate Python setup
uv sync --frozen --all-extras

# Simulate frontend setup
cd frontend && npm ci --prefer-offline --no-audit
```

## Troubleshooting

### Common Issues

**Workflow Timeouts**:

- Check logs for hanging operations
- Review timeout values in workflow files
- Consider increasing timeout for legitimate long operations

**Cache Misses**:

- Verify cache keys include all relevant files
- Check for changes in lock files
- Review cache restoration logs

**Test Failures in CI but not Local**:

- Check for environment-specific issues
- Verify service health in CI logs
- Review parallel test isolation

**Skipped Tests**:

- Check change detection filters
- Verify file paths in workflow triggers
- Use manual dispatch to force execution

### Debugging Workflows

**Download Artifacts**:

```bash
# Download test results and coverage
gh run download <run-id> -n pytest-results-unit-py3.12
```

**View Detailed Logs**:

```bash
# View specific job logs
gh run view <run-id> --log --job <job-id>
```

**Re-run with Debugging**:

```bash
# Re-run failed jobs with debug logging
gh workflow run test.yml -f debug=true
```

## Best Practices

### Workflow Design

1. **Fast Feedback**: Quality checks run first and fast
1. **Smart Skipping**: Only run tests for changed code
1. **Parallel Everything**: Maximize concurrent execution
1. **Cache Aggressively**: Cache dependencies, builds, and results
1. **Timeout Appropriately**: Prevent hanging and waste

### Performance Tips

1. **Use Composite Actions**: Reduce duplication and maintenance
1. **Implement Change Detection**: Skip unnecessary work
1. **Optimize Service Startup**: Parallel health checks
1. **Cache Docker Layers**: Speed up container builds
1. **Set Resource Limits**: Use appropriate runner sizes

### Security

1. **Scan Everything**: Multiple security tools at different stages
1. **Minimal Secrets**: Use GitHub tokens when possible
1. **Scoped Permissions**: Least privilege access
1. **Regular Updates**: Keep actions and dependencies current

### Maintenance

1. **Monitor Performance**: Track workflow execution times
1. **Review Timeouts**: Adjust based on actual execution
1. **Update Caches**: Clear stale caches periodically
1. **Test Changes**: Validate workflow updates in PRs

## Future Enhancements

### Planned Improvements

- **Multi-Architecture Builds**: ARM64 support for Docker images
- **Flaky Test Detection**: Automatic quarantine of unstable tests
- **Cost Optimization**: Detailed CI/CD spending analysis
- **Preview Environments**: Ephemeral environments for PRs

### Performance Goals

- **Sub-10 minute PR feedback**: For typical changes
- **50% cache hit rate**: For dependency installation
- **Zero hanging workflows**: With comprehensive timeouts
- **90% test relevance**: With smart change detection
